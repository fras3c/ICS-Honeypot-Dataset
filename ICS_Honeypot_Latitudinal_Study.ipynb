{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "91HkenPeS_Nw",
        "outputId": "9101c56a-d3ab-4370-da62-8f9050fc84d8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-de4d8f9a4797>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mroot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/gdrive/MyDrive/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "root_dir = \"/content/gdrive/MyDrive/\"\n",
        "base_dir = root_dir + 'JSONS/'\n",
        "os.listdir(base_dir)\n",
        "\n",
        "#Load malicious ip dataframe\n",
        "malicious_ips = pd.read_json(base_dir+\"malicious_ips.json\")\n",
        "malicious_ips.rename(columns = {0 : \"id.orig_h\"}, inplace = True)\n",
        "\n",
        "malicious_ips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41Sg8iCZd5jD"
      },
      "outputs": [],
      "source": [
        "\n",
        "def read_and_convert_timestamp(file_path):\n",
        "    # Read JSON file into a DataFrame\n",
        "    frame = pd.read_json(base_dir + file_path)\n",
        "\n",
        "    # Convert the 'ts' column to datetime format\n",
        "    frame['ts'] = pd.to_datetime(frame['ts'], format='%Y-%m-%dT%H:%M:%S.%f')\n",
        "\n",
        "    # Return the DataFrame with updated timestamp\n",
        "    return frame\n",
        "\n",
        "def filter_and_reset_index(frame, port, ip_filter, malicious_ips):\n",
        "    # Filter out rows with 'id.orig_h' not in the list of malicious IPs\n",
        "    filtered_good = frame[~frame['id.orig_h'].isin(malicious_ips['id.orig_h'])].reset_index(drop=True)\n",
        "\n",
        "    # Filter rows with 'id.orig_h' in the list of malicious IPs\n",
        "    filtered_malicious = frame[frame['id.orig_h'].isin(malicious_ips['id.orig_h'])].reset_index(drop=True)\n",
        "\n",
        "    # Return the filtered DataFrames for good and malicious traffic\n",
        "    return filtered_good, filtered_malicious\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-TP-8sAWbMV"
      },
      "outputs": [],
      "source": [
        "# Read JSON file into a DataFrame\n",
        "http_frame = pd.read_json(base_dir + \"http.json\")\n",
        "\n",
        "# Convert 'ts' column to datetime format\n",
        "http_frame['ts'] = pd.to_datetime(http_frame['ts'], format='%Y-%m-%dT%H:%M:%S.%f')\n",
        "\n",
        "# Filter HMI and PLC HTTP frames\n",
        "hmi_http = http_frame[((http_frame[\"id.resp_p\"].isin([8081, 8082])) & (http_frame[\"id.resp_h\"] == \"192.168.10.114\"))]\n",
        "plc_http = http_frame[(http_frame[\"id.resp_p\"] == 8080)]\n",
        "\n",
        "# Filter HMI HTTP frames for good and malicious IPs\n",
        "hmi_http_good = hmi_http[~hmi_http['id.orig_h'].isin(malicious_ips['id.orig_h'])].reset_index(drop=True)\n",
        "hmi_http_malicious = hmi_http[hmi_http['id.orig_h'].isin(malicious_ips['id.orig_h'])].reset_index(drop=True)\n",
        "\n",
        "# Filter PLC HTTP frames for good and malicious IPs\n",
        "plc_http_good = plc_http[~plc_http['id.orig_h'].isin(malicious_ips['id.orig_h'])].reset_index(drop=True)\n",
        "plc_http_malicious = plc_http[plc_http['id.orig_h'].isin(malicious_ips['id.orig_h'])].reset_index(drop=True)\n",
        "\n",
        "\n",
        "# Read Modbus JSON file into a DataFrame\n",
        "modbus_frame = pd.read_json(base_dir + \"modbus.json\")\n",
        "\n",
        "# Convert 'ts' column to datetime format if needed\n",
        "modbus_frame['ts'] = pd.to_datetime(modbus_frame['ts'], format='%Y-%m-%dT%H:%M:%S.%f')\n",
        "\n",
        "# Apply filters and reset index for good and malicious Modbus frames\n",
        "modbus_good = modbus_frame[~modbus_frame['id.orig_h'].isin(malicious_ips['id.orig_h'])].reset_index(drop=True)\n",
        "modbus_malicious = modbus_frame[modbus_frame['id.orig_h'].isin(malicious_ips['id.orig_h'])].reset_index(drop=True)\n",
        "\n",
        "# Read S7Comm JSON file into a DataFrame\n",
        "s7comm_frame = pd.read_json(base_dir + \"s7comm.json\")\n",
        "\n",
        "# Convert 'ts' column to datetime format if needed\n",
        "s7comm_frame['ts'] = pd.to_datetime(s7comm_frame['ts'], format='%Y-%m-%dT%H:%M:%S.%f')\n",
        "s7comm_frame = s7comm_frame[(s7comm_frame[\"ts\"] > pd.to_datetime(\"2023-06-03T00:42:50.572273920\", format='%Y-%m-%dT%H:%M:%S.%f'))]\n",
        "# Apply filters and reset index for good and malicious S7Comm frames\n",
        "s7comm_good = s7comm_frame[~s7comm_frame['id.orig_h'].isin(malicious_ips['id.orig_h'])].reset_index(drop=True)\n",
        "s7comm_malicious = s7comm_frame[s7comm_frame['id.orig_h'].isin(malicious_ips['id.orig_h'])].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_t2DSExUhVUF"
      },
      "outputs": [],
      "source": [
        "# Print length of HTTP frames\n",
        "print(\"Length of HMI HTTP frames:\", len(hmi_http))\n",
        "print(\"Length of PLC HTTP frames:\", len(plc_http))\n",
        "print(\"Length of HMI HTTP good frames:\", len(hmi_http_good))\n",
        "print(\"Length of HMI HTTP malicious frames:\", len(hmi_http_malicious))\n",
        "print(\"Length of PLC HTTP good frames:\", len(plc_http_good))\n",
        "print(\"Length of PLC HTTP malicious frames:\", len(plc_http_malicious))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnNIZWtVhe5t"
      },
      "outputs": [],
      "source": [
        "# Print length of Modbus frames\n",
        "print(\"Length of Modbus frames:\", len(modbus_frame))\n",
        "print(\"Length of Modbus good frames:\", len(modbus_good))\n",
        "print(\"Length of Modbus malicious frames:\", len(modbus_malicious))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFL0T4UphhvI"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Print length of S7Comm frames\n",
        "print(\"Length of S7Comm frames:\", len(s7comm_frame))\n",
        "print(\"Length of S7Comm good frames:\", len(s7comm_good))\n",
        "print(\"Length of S7Comm malicious frames:\", len(s7comm_malicious))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBqBpGTshs6y"
      },
      "outputs": [],
      "source": [
        "labels = [\n",
        "     'HTTP HMI (benign)',\n",
        "    'HTTP PLC (benign)',\n",
        "    'MODBUS (benign)',\n",
        "    'S7Comm (benign)',\n",
        "    'HTTP HMI (malicious)',\n",
        "    'HTTP PLC (malicious)',\n",
        "    'MODBUS (malicious)',\n",
        "    'S7Comm (malicious)'\n",
        "]\n",
        "\n",
        "#labels = ['IT (benign)', 'ICS (benign)', 'IT (malicious)', 'ICS (malicious)']\n",
        "#Specify the session time limit in seconds for each protocol/container type here.\n",
        "bounds = dict()\n",
        "bounds['HTTP HMI (benign)'] = 30*60\n",
        "bounds['HTTP PLC (benign)'] = 5\n",
        "bounds['MODBUS (benign)'] = 1\n",
        "bounds['S7Comm (benign)'] = 1\n",
        "\n",
        "bounds['HTTP HMI (malicious)'] = 30*60\n",
        "bounds['HTTP PLC (malicious)'] = 5\n",
        "bounds['MODBUS (malicious)'] = 1\n",
        "bounds['S7Comm (malicious)'] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNoYp-0aiEIw"
      },
      "outputs": [],
      "source": [
        "def split_sessions_start_time(label, table):\n",
        "    time_delta = pd.Timedelta(seconds=bounds[label])\n",
        "\n",
        "    # Sort the DataFrame\n",
        "    table.sort_values(['id.orig_h', 'id.resp_h', 'id.orig_p', 'id.resp_p', 'ts'], inplace=True)\n",
        "\n",
        "    sessions = []\n",
        "\n",
        "    # Group by source ip, port and destination ip, port\n",
        "    for _, group in tqdm(table.groupby(['id.orig_h', 'id.resp_h', 'id.orig_p', 'id.resp_p'])):\n",
        "        if group.empty:\n",
        "            continue\n",
        "\n",
        "        session = []\n",
        "        #Take time of previous request\n",
        "        last_time = group.iloc[0]['ts']\n",
        "\n",
        "        for _, row in group.iterrows():\n",
        "          #If the timestamp of the current request exceeds the sum of the previous timestamp and the specified time threshold, add the session to the list of sessions.\n",
        "            if row['ts'] > last_time + time_delta:\n",
        "                sessions.append(pd.DataFrame(session))\n",
        "                session = []\n",
        "\n",
        "            last_time = row['ts']\n",
        "            session.append(row)\n",
        "\n",
        "        if session:\n",
        "            sessions.append(pd.DataFrame(session))\n",
        "\n",
        "    return sessions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikk0253wiJgC"
      },
      "outputs": [],
      "source": [
        "interaction_list = [(labels[0] , split_sessions_start_time(labels[0], hmi_http_good)),\n",
        "                    (labels[1] , split_sessions_start_time(labels[1], plc_http_good)),\n",
        "                    (labels[2], split_sessions_start_time(labels[2], modbus_good)),\n",
        "                    (labels[3], split_sessions_start_time(labels[3], s7comm_good)),\n",
        "                    (labels[4] , split_sessions_start_time(labels[4], hmi_http_malicious)),\n",
        "                    (labels[5] , split_sessions_start_time(labels[5], plc_http_malicious)),\n",
        "                    (labels[6], split_sessions_start_time(labels[6], modbus_malicious)),\n",
        "                    (labels[7], split_sessions_start_time(labels[7], s7comm_malicious))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5uZaFu0J_dI"
      },
      "source": [
        "6.2.1 RQ5: From which geographic regions do the observed ICS\n",
        "interactions originate compared to IT interactions?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(interaction_list)):\n",
        "    print(interaction_list[i][0], len(interaction_list[i][1]))"
      ],
      "metadata": {
        "id": "3dgAC9oZYUna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCZTZmu5ID39"
      },
      "outputs": [],
      "source": [
        "def count_interactions(dfx):\n",
        "  mappa_ip_count = dict()\n",
        "  for i in range(len(dfx)):\n",
        "      x = dfx[i].groupby(['id.orig_h']).count()['ts'].reset_index()\n",
        "      x_ip_seen = set()\n",
        "      for ind in x.index:\n",
        "          ip = x['id.orig_h'][ind]\n",
        "          if ip not in x_ip_seen:\n",
        "              if ip in mappa_ip_count:\n",
        "                  mappa_ip_count[ip] += 1\n",
        "              else:\n",
        "                  mappa_ip_count[ip] = 1\n",
        "              x_ip_seen.add(ip)\n",
        "\n",
        "  return mappa_ip_count"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_sess_lengths = lambda lst: pd.Series([x.shape[0] for x in lst])"
      ],
      "metadata": {
        "id": "YeaFsvXRUW7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table = []\n",
        "ind = []\n",
        "for label, values in interaction_list:\n",
        "    tbl_data = get_sess_lengths(values)\n",
        "    table.append([tbl_data.min(),\n",
        "                  tbl_data.max(),\n",
        "                  tbl_data.median(),\n",
        "                  tbl_data.quantile(0.25),\n",
        "                  tbl_data.quantile(0.75),\n",
        "                  tbl_data.shape[0]])\n",
        "    ind.append(label)\n",
        "pd.DataFrame(table,\n",
        "             index=ind,\n",
        "             columns = ['min', 'max', 'median', 'Q1', 'Q3', 'count'])"
      ],
      "metadata": {
        "id": "wbNZ10l8T8lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7XBE_jdBhj9"
      },
      "outputs": [],
      "source": [
        "hmi_http_good = pd.DataFrame(count_interactions(interaction_list[0][1]).items(), columns=['ip', 'interactions'])\n",
        "plc_http_good = pd.DataFrame(count_interactions(interaction_list[1][1]).items(), columns=['ip', 'interactions'])\n",
        "\n",
        "hmi_http_malicious = pd.DataFrame(count_interactions(interaction_list[4][1]).items(), columns=['ip', 'interactions'])\n",
        "plc_http_malicious = pd.DataFrame(count_interactions(interaction_list[5][1]).items(), columns=['ip', 'interactions'])\n",
        "\n",
        "IT_good = pd.concat([hmi_http_good,plc_http_good])\n",
        "IT_malicious = pd.concat([hmi_http_malicious,plc_http_malicious])\n",
        "\n",
        "modbus_good = pd.DataFrame(count_interactions(interaction_list[2][1]).items(), columns=['ip', 'interactions'])\n",
        "s7comm_good = pd.DataFrame(count_interactions(interaction_list[3][1]).items(), columns=['ip', 'interactions'])\n",
        "modbus_malicious = pd.DataFrame(count_interactions(interaction_list[6][1]).items(), columns=['ip', 'interactions'])\n",
        "s7comm_malicious = pd.DataFrame(count_interactions(interaction_list[7][1]).items(), columns=['ip', 'interactions'])\n",
        "\n",
        "ICS_good = pd.concat([modbus_good, s7comm_good])\n",
        "ICS_malicious = pd.concat([modbus_malicious, s7comm_malicious])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrf_BfqTKJUt"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ics_good = ICS_good\n",
        "ics_bad = ICS_malicious\n",
        "ics = pd.concat([ics_good,ics_bad])\n",
        "ics.rename(columns={'id.orig_h':'ip'}, inplace=True)\n",
        "ics.rename(columns={'count':'requests'}, inplace=True)\n",
        "\n",
        "it_good = IT_good\n",
        "it_bad = IT_malicious\n",
        "it = pd.concat([it_good,it_bad])\n",
        "it.rename(columns={'id.orig_h':'ip'}, inplace=True)\n",
        "it.rename(columns={'count':'requests'}, inplace=True)\n",
        "\n",
        "#i need to drop the request column and replace it with the interaction column coming from the IPvsInteractions.csv\n",
        "malicious_ips = pd.read_json(base_dir+\"malicious_ips.json\")\n",
        "\n",
        "ipvsinteraction = pd.read_csv(base_dir+\"IPvsInteractions.csv\")\n",
        "ipvsinteraction.rename(columns={'count':'interactions'}, inplace=True)\n",
        "ipvsinteraction.rename(columns={'id.orig_h':'ip'}, inplace=True)\n",
        "\n",
        "ics = pd.merge(ics, ipvsinteraction, on='ip', how='left')\n",
        "it = pd.merge(it, ipvsinteraction, on='ip', how='left')\n",
        "\n",
        "#drop the requests column\n",
        "\n",
        "#rename the interactions column in requests\n",
        "ics.rename(columns={'interactions':'requests'}, inplace=True)\n",
        "it.rename(columns={'interactions':'requests'}, inplace=True)\n",
        "\n",
        "geo = pd.read_csv(base_dir+\"merged.csv\")\n",
        "#drop all the columns but ip, classification, country, country_code, organization, actor and organization\n",
        "geo = geo[['ip','classification','country','country_code','organization','actor']]\n",
        "nan = geo[geo.isna().any(axis=1)]\n",
        "\n",
        "#how many ips in ics are not present in geo\n",
        "ics_not_in_geo = ics[~ics.ip.isin(geo.ip)]\n",
        "#how many ips in it are not present in geo\n",
        "it_not_in_geo = it[~it.ip.isin(geo.ip)]\n",
        "\n",
        "#I need to merge the geo info with the ics and the geo info\n",
        "#The ip which are not present in geo will appear in the new dataframe as NaN\n",
        "ics_geo = pd.merge(ics, geo, on='ip', how='left')\n",
        "\n",
        "#get the ips which are not present in geo, where just country is NaN\n",
        "# assuming the dataframe is called df and the column you want to check is called 'column_name'\n",
        "ics_nan = ics_geo.loc[ics_geo['country'].isnull()]\n",
        "it_geo = pd.merge(it, geo, on='ip', how='left')\n",
        "it_nan = it_geo.loc[it_geo['country'].isnull()]\n",
        "\n",
        "\n",
        "error = 0\n",
        "for ip in ics_nan.ip:\n",
        "    respone = \"\"\n",
        "    try:\n",
        "        respone = requests.get(f'https://ipinfo.io/{ip}?token=#############')\n",
        "        print(f'https://ipinfo.io/{ip}?token=################')\n",
        "        print(respone.json())\n",
        "    except:\n",
        "        print(respone)\n",
        "        print(ip)\n",
        "        error += 1\n",
        "    try:\n",
        "        ics_geo.loc[ics_geo['ip'] == ip, 'country'] = respone.json()['region']\n",
        "    except:\n",
        "        ics_geo.loc[ics_geo['ip'] == ip, 'country'] = 'Unknown'\n",
        "        error += 1\n",
        "    try:\n",
        "        ics_geo.loc[ics_geo['ip'] == ip, 'country_code'] = respone.json()['country']\n",
        "    except:\n",
        "        ics_geo.loc[ics_geo['ip'] == ip, 'country_code'] = 'Unknown'\n",
        "        error += 1\n",
        "    try:\n",
        "        ics_geo.loc[ics_geo['ip'] == ip, 'organization'] = respone.json()['org']\n",
        "        error += 1\n",
        "    except:\n",
        "        ics_geo.loc[ics_geo['ip'] == ip, 'organization'] = 'Unknown'\n",
        "        error += 1\n",
        "    ics_geo.loc[ics_geo['ip'] == ip, 'actor'] = 'Unknown'\n",
        "    ics_geo.loc[ics_geo['ip'] == ip, 'classification'] = 'Unknown'\n",
        "\n",
        "print('ICSerror: ',error)\n",
        "\n",
        "error = 0\n",
        "for ip in it_nan.ip:\n",
        "    try:\n",
        "        respone = requests.get(f'https://ipinfo.io/{ip}?token=#############')\n",
        "    except:\n",
        "        print('EEError')\n",
        "        print(ip)\n",
        "        print(respone)\n",
        "        error += 1\n",
        "    try:\n",
        "        it_geo.loc[it_geo['ip'] == ip, 'country'] = respone.json()['region']\n",
        "    except:\n",
        "        it_geo.loc[it_geo['ip'] == ip, 'country'] = 'Unknown'\n",
        "        error += 1\n",
        "    try:\n",
        "        it_geo.loc[it_geo['ip'] == ip, 'country_code'] = respone.json()['country']\n",
        "    except:\n",
        "        it_geo.loc[it_geo['ip'] == ip, 'country_code'] = 'Unknown'\n",
        "        error += 1\n",
        "    try:\n",
        "        it_geo.loc[it_geo['ip'] == ip, 'organization'] = respone.json()['org']\n",
        "    except:\n",
        "        it_geo.loc[it_geo['ip'] == ip, 'organization'] = 'Unknown'\n",
        "        error += 1\n",
        "    it_geo.loc[it_geo['ip'] == ip, 'actor'] = 'Unknown'\n",
        "    it_geo.loc[it_geo['ip'] == ip, 'classification'] = 'Unknown'\n",
        "\n",
        "print('ITerror: ',error)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZUpKGxqNRqv"
      },
      "outputs": [],
      "source": [
        "it = it_geo\n",
        "ics = ics_geo\n",
        "\n",
        "\n",
        "\n",
        "#group by country print the number or IP and the sum of requests sorted by requests\n",
        "it_grouped_sortedReq = it.groupby(['country']).agg({'ip':'count','interactions_x':'sum'}).sort_values(by=['interactions_x'],ascending=False)\n",
        "ics_grouped_sortedReq = ics.groupby(['country']).agg({'ip':'count','interactions_x':'sum'}).sort_values(by=['interactions_x'],ascending=False)\n",
        "\n",
        "#group by country print the number or IP and the sum of requests sorted by IP\n",
        "it_grouped_sortedIP = it.groupby(['country']).agg({'ip':'count','interactions_x':'sum'}).sort_values(by=['ip'],ascending=False)\n",
        "ics_grouped_sortedIP = ics.groupby(['country']).agg({'ip':'count','interactions_x':'sum'}).sort_values(by=['ip'],ascending=False)\n",
        "\n",
        "print(it_grouped_sortedReq)\n",
        "print(ics_grouped_sortedReq)\n",
        "print(it_grouped_sortedIP)\n",
        "print(ics_grouped_sortedIP)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcIWQAAnyCLU"
      },
      "source": [
        "RQ6: From which actors do the observed ICS interactions originate compared to IT interactions?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DWdJ0lryajU"
      },
      "outputs": [],
      "source": [
        "it = it_geo\n",
        "ics = ics_geo\n",
        "\n",
        "#for each row if actor = unknown then copy the value from organization to actor\n",
        "for index, row in it.iterrows():\n",
        "    if row['actor'] == 'Unknown' or row['actor'] == 'unknown':\n",
        "        it.loc[index,'actor'] = row['organization']\n",
        "\n",
        "for index, row in ics.iterrows():\n",
        "    if row['actor'] == 'Unknown' or row['actor'] == 'unknown':\n",
        "        ics.loc[index,'actor'] = row['organization']\n",
        "\n",
        "#remove \" from actor column\n",
        "it['actor'] = it['actor'].str.replace('\"','')\n",
        "ics['actor'] = ics['actor'].str.replace('\"','')\n",
        "it['organization'] = it['organization'].str.replace('\"','')\n",
        "ics['organization'] = ics['organization'].str.replace('\"','')\n",
        "\n",
        "#group by actor print the number or IP and the sum of requests sorted by requests\n",
        "it_grouped_sortedReq = it.groupby(['actor']).agg({'ip':'count','interactions_x':'sum'}).sort_values(by=['interactions_x'],ascending=False)\n",
        "ics_grouped_sortedReq = ics.groupby(['actor']).agg({'ip':'count','interactions_x':'sum'}).sort_values(by=['interactions_x'],ascending=False)\n",
        "\n",
        "#group by actor print the number or IP and the sum of requests sorted by IP\n",
        "it_grouped_sortedIP = it.groupby(['actor']).agg({'ip':'count','interactions_x':'sum'}).sort_values(by=['ip'],ascending=False)\n",
        "ics_grouped_sortedIP = ics.groupby(['actor']).agg({'ip':'count','interactions_x':'sum'}).sort_values(by=['ip'],ascending=False)\n",
        "\n",
        "print(it_grouped_sortedReq)\n",
        "print(ics_grouped_sortedReq)\n",
        "print(it_grouped_sortedIP)\n",
        "print(ics_grouped_sortedIP)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyG2wUNtycMO"
      },
      "source": [
        "RQ7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXFLGngryj_8"
      },
      "outputs": [],
      "source": [
        "it = it_geo\n",
        "ics = ics_geo\n",
        "\n",
        "#see which ips are in both datasets, and create  a new dataframe with only those ips and the respective country\n",
        "it_ics = pd.merge(it, ics, on='ip', how='inner')\n",
        "it_ics = it_ics[['ip', 'country_x']]\n",
        "it_ics = it_ics.rename(columns={'country_x': 'country'})\n",
        "it_ics = it_ics.drop_duplicates(subset=['ip'])\n",
        "\n",
        "print(it_ics)\n",
        "\n",
        "ipvsinteraction = pd.read_csv(base_dir+\"IPvsInteractions.csv\")\n",
        "ipvsinteraction.rename(columns={'count':'interactions'}, inplace=True)\n",
        "ipvsinteraction.rename(columns={'id.orig_h':'ip'}, inplace=True)\n",
        "\n",
        "#merge the new dataframe with the interactions\n",
        "it_ics = pd.merge(it_ics, ipvsinteraction, on='ip', how='left')\n",
        "#sort by interactions\n",
        "it_ics = it_ics.sort_values(by=['interactions'],ascending=False)\n",
        "print(it_ics)\n",
        "\n",
        "#group by country and sum the interactions\n",
        "it_ics_grouped = it_ics.groupby(['country']).agg({'interactions':'sum'}).sort_values(by=['interactions'],ascending=False)\n",
        "print(it_ics_grouped)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}